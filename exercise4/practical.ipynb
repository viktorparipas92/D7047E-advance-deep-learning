{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Task 1 - Train a char-RNN to generate sequences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nn, zeros\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograd\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Variable\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn, zeros\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from helpers import (\n",
    "    ALL_CHARACTERS,\n",
    "    N_CHARACTERS,\n",
    "    convert_to_char_tensor,\n",
    "    read_file,\n",
    "    time_since,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\n",
    "    'cuda' if torch.cuda.is_available()\n",
    "    else 'mps' if torch.backends.mps.is_available()\n",
    "    else 'cpu'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First let's define the char-RNN model based on the `char-rnn.pytorch` repository"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size=N_CHARACTERS,\n",
    "        hidden_size=50,\n",
    "        output_size=N_CHARACTERS,\n",
    "        model='gru',\n",
    "        n_layers=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model.lower()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        if self.model == 'gru':\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        elif self.model == 'lstm':\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "\n",
    "    def forward(self, input_, hidden):\n",
    "        encoded = self.encoder(input_)\n",
    "\n",
    "        batch_size = input_.size(0)\n",
    "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
    "        output = self.decoder(output.view(batch_size, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def forward2(self, input_, hidden):\n",
    "        encoded = self.encoder(input_.view(1, -1))\n",
    "        output, hidden = self.rnn(encoded.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden_layer(self, batch_size):\n",
    "        zeros_matrix = zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        if self.model == 'lstm':\n",
    "            return Variable(zeros_matrix), Variable(zeros_matrix)\n",
    "\n",
    "        return Variable(zeros_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's define the function to train the char-RNN model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_char_rnn(\n",
    "    model: CharRNN,\n",
    "    input_,\n",
    "    target,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    batch_size=100,\n",
    "    chunk_length=200,\n",
    "):\n",
    "    hidden_layer = model.init_hidden_layer(batch_size)\n",
    "    hidden_layer.to(DEVICE)\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "    for i in range(chunk_length):\n",
    "        output_layer, hidden_layer = model(input_[:, i], hidden_layer)\n",
    "        loss += criterion(output_layer.view(batch_size, -1), target[:, i])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.data[0] / chunk_length"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate(\n",
    "    model: CharRNN,\n",
    "    prime_string='A',\n",
    "    predict_length : int = 100,\n",
    "    temperature=0.8,\n",
    "):\n",
    "    hidden_layer = model.init_hidden_layer(1)\n",
    "    prime_input = Variable(convert_to_char_tensor(prime_string).unsqueeze(0))\n",
    "\n",
    "    hidden_layer = hidden_layer.to(DEVICE)\n",
    "    prime_input = prime_input.to(DEVICE)\n",
    "    predicted = prime_string\n",
    "\n",
    "    for i in range(len(prime_string) - 1):\n",
    "        _, hidden_layer = model(prime_input[:, i], hidden_layer)\n",
    "\n",
    "    input_ = prime_input[:, -1]\n",
    "    for p in range(predict_length):\n",
    "        output, hidden_layer = model(input_, hidden_layer)\n",
    "\n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_distribution = output.data.view(-1).div(temperature).exp()\n",
    "        top_index = torch.multinomial(output_distribution, 1)[0]\n",
    "\n",
    "        predicted_char = ALL_CHARACTERS[top_index]\n",
    "        predicted += predicted_char\n",
    "        input_ = Variable(convert_to_char_tensor(predicted_char).unsqueeze(0))\n",
    "        input_.to(DEVICE)\n",
    "\n",
    "    return predicted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save(model, filename):\n",
    "    filename = os.path.splitext(\n",
    "        os.path.basename(filename)\n",
    "    )[0]\n",
    "    filename_with_extension = f'{filename}.pt'\n",
    "    torch.save(model, filename_with_extension)\n",
    "    print(f'Saved as {filename_with_extension}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def random_training_set(file, file_length, chunk_length, batch_size):\n",
    "    input_ = torch.LongTensor(batch_size, chunk_length)\n",
    "    target = torch.LongTensor(batch_size, chunk_length)\n",
    "    for batch_index in range(batch_size):\n",
    "        start_index = random.randint(0, file_length - chunk_length)\n",
    "        end_index = start_index + chunk_length + 1\n",
    "        chunk = file[start_index : end_index]\n",
    "        input_[batch_index] = convert_to_char_tensor(chunk[:-1])\n",
    "        target[batch_index] = convert_to_char_tensor(chunk[1:])\n",
    "\n",
    "    input_ = Variable(input_).to(DEVICE)\n",
    "    target = Variable(target).to(DEVICE)\n",
    "\n",
    "    return input_, target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "n_layers = 1\n",
    "model_type = 'lstm'\n",
    "learning_rate = 0.01\n",
    "n_epochs = 2000\n",
    "batch_size = 100\n",
    "chunk_length = 200\n",
    "\n",
    "predict_length = 100\n",
    "\n",
    "filename = 'model'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file, file_length = read_file(filename)\n",
    "\n",
    "decoder = CharRNN(\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=N_CHARACTERS,\n",
    "    model=model_type,\n",
    "    n_layers=n_layers,\n",
    ")\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_average = 0\n",
    "\n",
    "try:\n",
    "    print(f'Training for {n_epochs} epochs...')\n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "        loss = train_char_rnn(\n",
    "            decoder,\n",
    "            *random_training_set(file, file_length, chunk_length, batch_size),\n",
    "            decoder_optimizer,\n",
    "            criterion,\n",
    "            batch_size=batch_size,\n",
    "            chunk_length=chunk_length,\n",
    "        )\n",
    "        loss_average += loss\n",
    "\n",
    "        if not epoch % 100:\n",
    "            print(f'[{time_since(start)} ({epoch} {epoch / n_epochs * 100}%) {loss:.4f}]')\n",
    "            print(f'{generate(decoder, \"Wh\", predict_length)} \\n')\n",
    "\n",
    "    print('Saving...')\n",
    "    save(decoder, filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}