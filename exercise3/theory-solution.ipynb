{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac8fd8d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1) What are the advantages of t-SNE over PCA?\n",
    "\n",
    "- t-SNE is better at capturing non-linear relationships between data points, while PCA assumes that the relationships are linear.\n",
    "\n",
    "- t-SNE can preserve the local structure of the data, which is useful when analyzing complex datasets with many clusters or subgroups.\n",
    "\n",
    "- t-SNE produces a probability distribution that can be used to measure the similarity between data points, while PCA only produces a linear transformation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "191edcb3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a38ecba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_pairwise_similarities(x, y):\n",
    "    \"\"\"\n",
    "    Calculates the pairwise similarities for P and Q given the high-dimensional\n",
    "    and low-dimensional embeddings, respectively.\n",
    "    \"\"\"\n",
    "    # Compute pairwise distances\n",
    "    distances_x = squareform(pdist(x, 'euclidean'))\n",
    "    distances_y = squareform(pdist(y, 'euclidean'))\n",
    "    \n",
    "    # Compute Gaussian similarities for P\n",
    "    variance_x = np.var(distances_x)\n",
    "    P = np.exp(-distances_x ** 2 / (2 * variance_x))\n",
    "    np.fill_diagonal(P, 0)\n",
    "    P /= np.sum(P)\n",
    "    \n",
    "    # Compute Student t-distribution similarities for Q\n",
    "    # Picked this due to crowding problem for Gaussian\n",
    "     \n",
    "    dof = 1  # Degrees of freedom for Student t-distribution\n",
    "    t = 1 / (1 + (distances_y ** 2 / dof))\n",
    "    np.fill_diagonal(t, 0)\n",
    "    Q = t / np.sum(t)\n",
    "    return P, Q\n",
    "\n",
    "\n",
    "def kl_divergence(prob_dist_1, prob_dist_2, eps=1e-10):\n",
    "    prob_dist_2 = np.clip(prob_dist_2, eps, None)  # Clip Q to avoid log(0)\n",
    "    prob_dist_1 = np.clip(prob_dist_1, eps, None)  # Clip P to avoid log(0)\n",
    "    return np.sum(prob_dist_1 * np.log(prob_dist_1 / prob_dist_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ef7414e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1 loss: 0.43315572944277536\n"
     ]
    }
   ],
   "source": [
    "# Scenario 1: a, b, and c are all close to each other in the low-dimensional space, \n",
    "# but a and b are very close to each other in the high-dimensional space while c is far away\n",
    "\n",
    "x1 = np.array([[1, 2, 3], [2, 3, 4], [100, 120, 130]])\n",
    "y1 = np.array([[0.1, 0.2], [0.2, 0.3], [0.3, 0.4]])\n",
    "\n",
    "p1, q1 = calculate_pairwise_similarities(x1, y1)\n",
    "loss1 = kl_divergence(p1, q1)\n",
    "print(\"Scenario 1 loss:\", loss1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd26b13f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the first scenario where a, b, and c are all close to each other in the low-dimensional space, the pairwise similarities between them will be high, since they are close to each other. However, the pairwise similarities between a and b in the high-dimensional space were very high, while the similarity between c and either a or b was very low. As a result, the loss function will be high because there is a mismatch between the pairwise similarities in the high-dimensional space and the low-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfe432c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 2 loss: 1.1037919886644614\n"
     ]
    }
   ],
   "source": [
    "# Scenario 2: a and b are close to each other in the low-dimensional space, but c is far away from them\n",
    "x2 = np.array([[1, 2, 3], [2, 3, 4], [100, 120, 130]])\n",
    "y2 = np.array([[0.1, 0.2], [0.2, 0.3], [55, 45]])\n",
    "\n",
    "p2, q2 = calculate_pairwise_similarities(x2, y2)\n",
    "loss2 = kl_divergence(p2, q2)\n",
    "print(\"Scenario 2 loss:\", loss2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cab3b7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The KL divergence is likely to be relatively low, indicating that the t-SNE algorithm is able to effectively represent the data in the low-dimensional space,since the pairwise similarities between a and b are high in both the high-dimensional and low-dimensional spaces, and the pairwise similarities between c and a (or c and b) are low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0133a01a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 3 loss: 0.30040886086641033\n"
     ]
    }
   ],
   "source": [
    "# Scenario 3: a, b, and c are all far away from each other in the low-dimensional space\n",
    "x3 = np.array([[1, 2, 3], [2, 3, 4], [100, 120, 130]])\n",
    "y3 = np.array([[0.1, 0.2], [500.9, 500.8], [1000.5, 1000.6]])\n",
    "\n",
    "p3, q3 = calculate_pairwise_similarities (x3, y3)\n",
    "loss3 = kl_divergence(p3, q3)\n",
    "print(\"Scenario 3 loss:\", loss3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a96cdc8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since the pairwise similarities between a, b, and c are low in the low-dimensional space and the pairwise similarities between a and b are high in the high-dimensional space, the KL divergence is likely to be relatively high, indicating that the t-SNE algorithm may have difficulty representing the data in the low-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42d99471",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 4 loss: 6.5455777119206315\n"
     ]
    }
   ],
   "source": [
    "# Scenario 4: a is far away from both b and c, which are close to each other in the low-dimensional space\n",
    "x4 = np.array([[1, 2, 3], [2, 3, 4], [100, 120, 130]])\n",
    "y4 = np.array([[0.1, 0.2], [58.8, 58.9], [58.9, 60.0]])\n",
    "\n",
    "p4, q4 = calculate_pairwise_similarities(x4, y4)\n",
    "loss4 = kl_divergence(p4, q4)\n",
    "print(\"Scenario 4 loss:\", loss4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83b5db",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since the pairwise similarities between a, b, and c are low in the low-dimensional space and the pairwise similarities between b and c are high in the high-dimensional space, the KL divergence is likely to be relatively high, indicating that the t-SNE algorithm may have difficulty representing the data in the low-dimensional space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}