{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "012db474-f68c-4778-82fe-ec00d263d1e5",
   "metadata": {},
   "source": [
    "# Pneumonia Detection with Chest X-ray Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f72bd4-32d9-4376-b10f-5c2c009c6340",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c126f6-d5f9-4ba0-8ec7-1bd51c64216c",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14cd6eb1-fdb8-41f8-ad47-6e1ea8aa78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from itertools import islice\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import sys\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68daf55c-dfdf-442c-9f90-1de2bbf9ed6a",
   "metadata": {},
   "source": [
    "### Using GPU for training if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5554672a-ce57-4062-892c-935f1169c6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11\n",
      "PyTorch version: 2.0.1\n",
      "Torchvision version: 0.15.2\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f'Python version: {sys.version_info.major}.{sys.version_info.minor}')\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'Torchvision version: {torchvision.__version__}')\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    elif torch.backends.mps.is_built():\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "    return device\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984107fb-6c26-4203-8828-98f67b02c1c8",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69005da3-4d04-4fe5-94a9-fcef1988127b",
   "metadata": {},
   "source": [
    "### Find smallest image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd92419-9524-4cf0-9230-a4423ba97181",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER = 'dataset/'\n",
    "TRAINING_FOLDER = f'{ROOT_FOLDER}train/'\n",
    "VALIDATION_FOLDER = f'{ROOT_FOLDER}val/'\n",
    "TEST_FOLDER = f'{ROOT_FOLDER}test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4adeb0a3-0431-4902-bb0c-c30d91a13516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384x127\n"
     ]
    }
   ],
   "source": [
    "def find_smallest_image(dataset_root: str) -> Tuple[str, Tuple[int, int]]:\n",
    "    smallest_width = smallest_height = None\n",
    "    smallest_filename = ''\n",
    "    \n",
    "    for root, _, filenames in os.walk(dataset_root):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                path = os.path.join(root, filename)\n",
    "                with Image.open(path) as image:\n",
    "                    width, height = image.size\n",
    "                    if (\n",
    "                        smallest_width is None\n",
    "                        or smallest_height is None\n",
    "                        or width * height < smallest_width * smallest_height\n",
    "                    ):\n",
    "                        smallest_width, smallest_height = (width, height)\n",
    "                        smallest_filename = filename\n",
    "\n",
    "    return smallest_filename, (smallest_width, smallest_height)\n",
    "\n",
    "\n",
    "_, smallest_size_training = find_smallest_image(TRAINING_FOLDER)\n",
    "_, smallest_size_validation = find_smallest_image(VALIDATION_FOLDER)\n",
    "_, smallest_size_test = find_smallest_image(TEST_FOLDER)\n",
    "smallest_width, smallest_height = min(\n",
    "    smallest_size_training, smallest_size_validation, smallest_size_test\n",
    ")\n",
    "print(f'{smallest_width}x{smallest_height}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f7b223-0585-49af-86c6-a0201d9ed4ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading and transforming the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f3a7d9-2c28-4424-ac4b-30fa712cb7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.random.manual_seed(RANDOM_SEED);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00eea270-54c7-4133-b741-9553b8810434",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 400\n",
    "ROTATION_DEGREE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95edb887-9c9e-479e-9918-f8a1cca4c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = transforms.Resize(size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "shared_transforms = [resize, to_tensor]\n",
    "\n",
    "training_transforms = transforms.Compose([\n",
    "    resize,\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=ROTATION_DEGREE),\n",
    "    to_tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9329124a-cf7d-4e68-904d-999b4e44f889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset root URL\n",
    "# https://ltu.app.box.com/s/ywboito9frcx5w4c4mzrrrl4qf2rh9u3/'\n",
    "\n",
    "training_dataset = ImageFolder(\n",
    "    root=TRAINING_FOLDER, transform=training_transforms\n",
    ")\n",
    "validation_dataset = ImageFolder(\n",
    "    root=VALIDATION_FOLDER, transform=transforms.Compose(shared_transforms))\n",
    "test_dataset = ImageFolder(\n",
    "    root=TEST_FOLDER, transform=transforms.Compose(shared_transforms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf1c5f9-6062-4ce8-af5f-0b96c256a169",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5216\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(training_dataset))\n",
    "print(len(validation_dataset))\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2e0d20a-4235-462b-af29-260e10914654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "892a66c6-419b-4586-9dd6-7833f2370d29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_loader = DataLoader(\n",
    "    training_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "validation_loader = DataLoader(\n",
    "    validation_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d2f069e-161d-4dc4-a6ed-44fd5b2ae1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = test_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59e33225-7bea-4d03-8a5d-d9f30ce35651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error \n",
    "\n",
    "class_id = 0\n",
    "while class_id < len(classes):\n",
    "    for images, labels in training_loader:\n",
    "        for image, label in zip(images, labels):\n",
    "            if class_id == label:\n",
    "                plt.figure(figsize=(8, 4))\n",
    "                plt.title(f'Class: {classes[class_id]}')\n",
    "                plt.imshow(image.permute(1, 2, 0))\n",
    "                plt.show()\n",
    "                \n",
    "                class_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e48951-145b-46ac-b8b3-a2ee8ffa6478",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86cf48-6dd2-442b-9b8d-d69cdddb092c",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05a682a4-1a52-4781-b0d2-79e7be737b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c3b0896-a314-454d-b609-cabb7fa72112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, criterion, optimizer, training_loader, validation_loader, num_epochs\n",
    "):\n",
    "    def train(epoch_loss):\n",
    "        model.train()\n",
    "        for _, (images, labels) in enumerate(training_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            training_prediction = model(images)\n",
    "            training_loss = criterion(training_prediction, labels)\n",
    "            training_loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += training_loss.item() * len(labels)\n",
    "        \n",
    "        epoch_loss /= len(training_loader)\n",
    "        writer.add_scalar(f'Loss/train:', epoch_loss, epoch)\n",
    "        print(\n",
    "            f'\\r[Training] Epoch [{epoch + 1} / {num_epochs}], '\n",
    "            f'Epoch Loss: {epoch_loss:.6f}'\n",
    "        )\n",
    "        \n",
    "    def validate():\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            validation_loss = 0\n",
    "\n",
    "            for _, (images, labels) in enumerate(validation_loader):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                validation_prediction = model(images)\n",
    "                validation_loss += criterion(\n",
    "                    validation_prediction, labels\n",
    "                ).item() * len(labels)\n",
    "\n",
    "            validation_loss /= len(validation_loader)\n",
    "            writer.add_scalar(f'Loss/train:', validation_loss, epoch)\n",
    "            print(\n",
    "                f'\\r[Validation] Epoch [{epoch + 1} / {num_epochs}], '\n",
    "                f'Validation Loss: {validation_loss:.6f}'\n",
    "            )\n",
    "    \n",
    "        return validation_loss\n",
    "    \n",
    "    best_validation_loss = None\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        train(epoch_loss)\n",
    "        validation_loss = validate()\n",
    "\n",
    "        if best_validation_loss is None or validation_loss < best_validation_loss:\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            print('\\t Better model found')\n",
    "    \n",
    "            best_validation_loss = validation_loss\n",
    "\n",
    "    writer.flush()\n",
    "    return best_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bc5bfe9-c1b3-4d3a-a182-4235ba80d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, criterion, test_loader):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    test_loss = 0\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, (images, labels) in enumerate(test_loader):\n",
    "            labels = labels.to(device)\n",
    "            num_total += labels.size(0)\n",
    "            true_labels.extend(labels.tolist())\n",
    "            \n",
    "            images = images.to(device)\n",
    "            prediction = model(images)\n",
    "            predicted_batch_labels = torch.argmax(prediction, dim=1)\n",
    "            num_correct += (predicted_batch_labels == labels).sum().item()\n",
    "            predicted_labels.extend(predicted_batch_labels.tolist())\n",
    "            \n",
    "            test_loss += criterion(prediction, labels).item() * len(labels)\n",
    "\n",
    "    accuracy = num_correct / num_total\n",
    "    test_loss /= num_total\n",
    "\n",
    "    print(\n",
    "        f'\\nAccuracy score: {accuracy:.1%} '\n",
    "        f'({num_correct} correct out of {num_total})')\n",
    "    \n",
    "    print(f'Test loss: {test_loss:.4f}')\n",
    "\n",
    "    return (\n",
    "        accuracy, \n",
    "        test_loss, \n",
    "        true_labels, \n",
    "        predicted_labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb0e76-20e7-4acb-b6e8-a276b119e99c",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "399a7567-80a8-4c7d-98de-4f623c0f7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 3\n",
    "LEARNING_RATE = 3e-5\n",
    "WEIGHT_DECAY = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64870dc2-32e8-4c9b-ae07-e709269709af",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52394098-14df-4541-a73e-8229d96ad376",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_model = models.resnet18(weights='DEFAULT')\n",
    "resnet34_model = models.resnet34(weights='DEFAULT')\n",
    "alexnet = models.alexnet(weights='DEFAULT')\n",
    "\n",
    "models_to_fine_tune = {\n",
    "    'ResNet-18': resnet18_model,\n",
    "    # 'ResNet-34': resnet34_model,\n",
    "    # 'AlexNet': alexnet,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bada2688-f0aa-4266-861f-0fda812d15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MODELS_TO_SKIP = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f9b9571-a93e-4dfe-a3b5-18d0a3d95624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ResNet-18']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_to_train = dict(\n",
    "    islice(models_to_fine_tune.items(), NUM_MODELS_TO_SKIP, None)\n",
    ")\n",
    "list(models_to_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ab129c3-135a-4cf2-8ba8-78849d57f971",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet-18: \n",
      "\n",
      "[Training] Epoch [1 / 3], Epoch Loss: 914.398868\n",
      "[Validation] Epoch [1 / 3], Validation Loss: 7.315018\n",
      "\t Better model found\n",
      "[Training] Epoch [2 / 3], Epoch Loss: 413.109320\n",
      "[Validation] Epoch [2 / 3], Validation Loss: 7.907164\n",
      "[Training] Epoch [3 / 3], Epoch Loss: 312.429014\n",
      "[Validation] Epoch [3 / 3], Validation Loss: 14.146242\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(classes)\n",
    "\n",
    "for model_name, model in models_to_train.items():\n",
    "    if model_name.startswith('ResNet'):\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif model_name == 'AlexNet':\n",
    "        model.classifier[6] = nn.Linear(\n",
    "            model.classifier[6].in_features, num_classes\n",
    "        )\n",
    "    \n",
    "    optimizer_for_fine_tuning = torch.optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=LEARNING_RATE, \n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "    )\n",
    "    print(f'Training {model_name}: \\n')\n",
    "    \n",
    "    best_fine_tuned_model_state = train_model(\n",
    "        model, \n",
    "        nn.CrossEntropyLoss(), \n",
    "        optimizer_for_fine_tuning, \n",
    "        training_loader, \n",
    "        validation_loader, \n",
    "        NUM_EPOCHS,\n",
    "    )\n",
    "    torch.save(best_fine_tuned_model_state, f'best-model-{model_name}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf63463c-48ed-4637-91dd-5599b555abb8",
   "metadata": {},
   "source": [
    "## Evaluating the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024984c0-08ed-436c-9ad4-08300956978c",
   "metadata": {},
   "source": [
    "### Loading the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cc38e56-8266-441e-921e-99ea0ddeb197",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ResNet-18']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_ft = nn.CrossEntropyLoss()\n",
    "\n",
    "best_models = {}\n",
    "for model_name, model in models_to_fine_tune.items():\n",
    "    try:\n",
    "        best_model_filename = f'best-model-{model_name}.pth'\n",
    "        best_model_state = torch.load(best_model_filename)\n",
    "        if model_name.startswith('ResNet'):\n",
    "            model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        elif model_name == 'AlexNet':\n",
    "            model.classifier[6] = nn.Linear(\n",
    "                model.classifier[6].in_features, num_classes\n",
    "            )\n",
    "        \n",
    "        model.load_state_dict(best_model_state)\n",
    "    except Exception as e:\n",
    "        print(f'Could not load model {model_name}: {e}')\n",
    "    \n",
    "    best_models[model_name] = model\n",
    "\n",
    "list(best_models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cbeafe-835b-4424-9c4f-23dfd6a8cd1b",
   "metadata": {},
   "source": [
    "### Evaluating performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "679e6b0f-313a-4cea-a42b-8324189e05f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_heatmap(\n",
    "    confusion_matrix: pd.DataFrame, model_name: str\n",
    "):\n",
    "    heatmap = sns.heatmap(confusion_matrix_dataframe, annot=True)\n",
    "    plt.ylabel('True label', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Predicted label', fontsize=14, fontweight='bold')\n",
    "    plt.title(f'Confusion matrix for {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_mislabeled_images(\n",
    "    test_loader, y_predicted, y_true, classes=classes\n",
    "):\n",
    "    for (images, labels) in test_loader:\n",
    "        for i, (predicted_label, true_label, image, label) in enumerate(\n",
    "            zip(y_predicted, y_true, images, labels)\n",
    "        ):\n",
    "            if predicted_label != true_label:\n",
    "                plt.figure(figsize=(8, 4))\n",
    "                plt.title(\n",
    "                    f'#{i} Predicted Label: \"{classes[predicted_label]}\" '\n",
    "                    f'True Label: \"{classes[true_label]}\" '\n",
    "                )\n",
    "                plt.imshow(image.permute(1, 2, 0))\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de0f3f-94fd-4c90-926c-972978b31c08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model ResNet-18:\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=50, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    print(f'\\nEvaluating model {model_name}:')\n",
    "    \n",
    "    _, _, y_true, y_predicted = test_model(\n",
    "        model, criterion_ft, test_loader\n",
    "    )\n",
    "    confusion_matrix_ = confusion_matrix(y_true, y_predicted)\n",
    "    confusion_matrix_dataframe = pd.DataFrame(\n",
    "        confusion_matrix_, \n",
    "        index=classes,\n",
    "        columns=classes,\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix_heatmap(\n",
    "        confusion_matrix_dataframe, model_name\n",
    "    )\n",
    "    \n",
    "    # plot_mislabeled_images(\n",
    "    #     test_loader, y_predicted, y_true, classes\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a76d92-f607-47ff-9bcd-1deff8f669b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
